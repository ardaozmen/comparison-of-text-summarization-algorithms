{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_fine_tuning_T5_tr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9d79f4e3ab44791a7ce0284ca2c20db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c807b061fa1b4eaa9cd890e5c31d340f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24785a5803f0474eb7ecd4b368ff3ec7",
              "IPY_MODEL_d13fd0af7da941e5905c6e4d545528ec"
            ]
          }
        },
        "c807b061fa1b4eaa9cd890e5c31d340f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24785a5803f0474eb7ecd4b368ff3ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_0ae4cfd2fc0649ec9b6166c9621f35f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.99MB of 0.99MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a775ac7967984587b9333ac7ecd49e72"
          }
        },
        "d13fd0af7da941e5905c6e4d545528ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_984748470cae4d36bb2e1a3d77fccd5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cfdf15b5f3e4c2f9fd1e63b446f2568"
          }
        },
        "0ae4cfd2fc0649ec9b6166c9621f35f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a775ac7967984587b9333ac7ecd49e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "984748470cae4d36bb2e1a3d77fccd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cfdf15b5f3e4c2f9fd1e63b446f2568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qNeV6slzBPE"
      },
      "source": [
        "This notebook based on this link: https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0mAdWlQOeGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b5ce4c12-56ab-453a-858f-2824cfc0af0d"
      },
      "source": [
        "#Reading the data\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('turkce_haber_4k.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\\nIğdır'da bir kişi, tartıştığı karısını silah...</td>\n",
              "      <td>Iğdır'da, Umut adlı erkek evi terk eden 1 çocu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\nCumhurbaşkanı Recep Tayyip Erdoğan'ın katılı...</td>\n",
              "      <td>Karsan Otomotiv'den yapılan açıklamada iş insa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\\nTürkiye'nin Otomobili'nin, Bilişim Vadisi'nd...</td>\n",
              "      <td>Türkiye'nin Otomobili'nin, Bilişim Vadisi'nde ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\nVan'ın Erciş ilçesinde evden çıktıktan sonra...</td>\n",
              "      <td>Van'ın Erciş ilçesinde evden çıktıktan sonra b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\\nSon dönemin parlayan yıldızlarından olan baş...</td>\n",
              "      <td>Dünyaca ünlü şarkıcı Rita Ora, annesi Vera Ora...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            Summary\n",
              "0           0  ...  Iğdır'da, Umut adlı erkek evi terk eden 1 çocu...\n",
              "1           1  ...  Karsan Otomotiv'den yapılan açıklamada iş insa...\n",
              "2           2  ...  Türkiye'nin Otomobili'nin, Bilişim Vadisi'nde ...\n",
              "3           3  ...  Van'ın Erciş ilçesinde evden çıktıktan sonra b...\n",
              "4           4  ...  Dünyaca ünlü şarkıcı Rita Ora, annesi Vera Ora...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1aWOwMYi-nV",
        "outputId": "4c0d237b-d9a1-40d5-a74b-d6df31fd38e1"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4484, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXyQ4Wr3h9oY"
      },
      "source": [
        "#Rename the column names\n",
        "df=df.rename(columns={\"Text\": \"ctext\", \"Summary\": \"text\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSRns0mZiZ5D"
      },
      "source": [
        "#Drop unnecessary column\n",
        "df=df.drop(columns=['Unnamed: 0'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xidLtAnejO2S"
      },
      "source": [
        "#Data cleaning\n",
        "df['text']=df['text'].apply(lambda x:' '.join(re.sub(r'(\\s)##\\w+##', r'\\1', x).split()))\n",
        "df['ctext']=df['ctext'].apply(lambda x:' '.join(re.sub(r'(\\s)##\\w+##', r'\\1', x).split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIz6iISIihHQ",
        "outputId": "1b825283-f423-417d-e69e-a9b4deb4cb6c"
      },
      "source": [
        "df['text'][0], df['ctext'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Iğdır'da, Umut adlı erkek evi terk eden 1 çocuk annesi eşini tabancayla vurarak öldürdü, ardından kendisini göğsünden vurdu. Yaralanan süpheli, hastanede tedaviye alındı.\",\n",
              " \"Iğdır'da bir kişi, tartıştığı karısını silahla vurarak öldürdükten sonra intihar girişiminde bulundu. EVİ TERK EDEN EŞİNİ IĞDIR'DA BULDUOlay, saat 18.00 sıralarında Kazım Karabekir Caddesi'nde meydana geldi. Ağrı'nın Doğubayazıt ilçesinde oturan 1 çocuk annesi Ebru A., yaklaşık 3 ay önce henüz bilinmeyen nedenle eşini terk edip, Iğdır'a geldi. Burada ev kiralayan Ebru A.'yı bulan eşi Umut A. kente geldi. Eşinin evine giden Umut A., kapıyı çalıp, içeri girdi. ARALARINDA TARTIŞMA ÇIKTI, EŞİNE ATEŞ ETTİBu sırada iddiaya göre, ikili arasında tartışma çıktı. Tartışmanın büyümesi üzerine Umut A., yanında getirdiği tabanca ile Ebru A.'ya ateş etti. Ebru A. kanlar içinde yere yığılırken, Umut A. kendisini de göğsünden vurdu. KADIN EVDE ÖLDÜ, ŞÜPHELİ HASTANEDE TEDAVİ GÖRÜYORSilah sesini duyan komşuların ihbarı üzerine olay yerine polis ve sağlık ekipleri sevk edildi. Polis, Ebru A.'yı banyoda, Umut A.'yı ise odada kanlar içinde buldu. Sağlık görevlilerince yapılan kontrolde Ebru A.'nın yaşamını yitirdiği belirlendi. Yaralı Umut A. ise kaldırıldığı Iğdır Devlet Hastanesinde ameliyata alındı. Çiftin çocuklarının olay sırasında bakıcıda olduğu öğrenildi. Kaynak: Demirören Haber Ajansı\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQzxxXbeVitp",
        "outputId": "b6587579-051e-4847-8ad1-4d924cd11216"
      },
      "source": [
        "df['text'][2], df['ctext'][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Türkiye'nin Otomobili'nin, Bilişim Vadisi'nde açılış töreni organizasyonunu gerçekleştiren YRD İstanbul'un Yönetim Kurulu Başkanı Fikret Karadeniz, yerli otomobilin 7 bölgeyi gezerek vatandaşlarla buluşacağını söyledi.\",\n",
              " 'Türkiye\\'nin Otomobili\\'nin, Bilişim Vadisi\\'ndeki açılış töreni organizasyonunu gerçekleştiren YRD İstanbul\\'un Yönetim Kurulu Başkanı Fikret Karadeniz, Türkiye\\'nin Otomobili\\'nin ön gösterim araçlarının henüz vatandaşlarla buluşması için erken olduğunu belirterek, \"Marka lansmanı daha sonraki bir aşama ve marka lansmanıyla birlikte bildiğim kadarıyla araçlar 7 bölgeyi dolaşacak ve vatandaşlarla buluşturulacak.\" dedi. \"AYNI HEYECANI BİZ DE YAŞAMAYA BAŞLADIK\"Türkiye\\'nin Otomobili ön gösterim aracı tanıtımı projesine yaklaşık 1,5 ay önce Sanayi ve Teknoloji Bakanı Mustafa Varank\\'ın talimatıyla başladıklarını aktaran Karadeniz, \"TOGG ekibiyle ben daha öncesinde tanışmıyordum. TOGG CEO\\'su Gürcan Bey ve ekibiyle tanışıp onların profesyonel yaklaşımlarını, heyecanlarını görünce aynı heyecanı biz de yaşamaya başladık. Gerçekten çok doğru ve başarılı bir ürün ortaya koymuşlardı. Ben şahsen kasım ayı başı gibi otomobilleri gördüm onların heyecanın nedenlerini çok net anladım ve bu heyecanı birebir yaşamaya ben de başladım.\" diye konuştu. 636 KİŞİLİK EKİPLE ETKİNLİK ALANI OLUŞTURULDUKaradeniz, bu heyecanı bir şekilde otomobillerle ilgili çok ayrıntı vermeden kendi ekibine de hissettirmeye başladığını ifade ederek, şunları söyledi: \"Sayın Bakan, projenin lansmanının Bilişim Vadisi\\'nde yapılmasını istiyordu. Çünkü TOGG\\'un yönetim merkezi binası orada. Ama burada maalesef böyle bir lansmanı yapabilecek fiziki olanaklar yeterli değildi, kapalı bir mekan yoktu. O nedenle daha önce şantiye alanı olarak kullanılan 17 bin metrekarelik bir alanı yeniden düzenleyerek, aşağı yukarı 11 bin 500 metrekarelik bir alanına asfalt dökerek, ulaşım olanaklarını planlayarak ve çadırlarla çözüm üreterek bir etkinlik alanı oluşturmaya başladık. Bu çalışma 636 kişilik bir ekiple bir buçuk aylık bir sürede ortaya çıktı. Bu süreçte TOGG ekibiyle tanıştıktan sonra bu etkinlikte birlikte çalıştığımız Capital Event ekibiyle de bir araya geldik. Biz teknik çözümler, mekan çözümleri, teknik prodüksiyon gibi işleri hallederken onlar da Kerem Oba ve Bülent Mursaloğlu, içerik çözümlerine yoğunlaştılar ve çok başarılı bir iş ortaya çıkardılar gerçekten.\" \"DÜNYADA KULLANILMAMIŞ ÇILGIN BİR YÖNTEM DENEDİK\"Kasım ayında otomobilleri gördüğünü ve işe başlarken TOGG ile bir gizlilik anlaşması yaptıklarını aktaran Karadeniz, aracı görmüş olmasının heyecanlarını daha da artırdığını ve işe daha farklı bir açıdan bakmalarını sağladığını vurguladı. Otomobilleri gördükten sonra işin ciddiyetini ve boyutunu biraz daha büyütmeye karar verdiklerini ve sahne tasarımlarını değiştirdiklerini anlatan Karadeniz, \"Başardığımızı düşündüğümüz, otomobillerin alttan yukarı çıkarak davetlilere gösterildiği sahne, bildiğim kadarıyla dünyada bugüne kadar kullanılan bir yöntem değil. Otomobil lansmanlarında benim araştırmalarımda ve gözlemlerimde de hep karşıma çıkan şey; sunumun belli bir aşamasında ya bir perdenin arkasından otomobiller çıkar, ya otomobilin üzerindeki örtüler kalkar ya da en iyi çözüm olarak sahnenin sağından ve solundan otomobiller çıkar. Biz farklı bir şey yapmak istedik. 2 otomobilimizi birden sunumlar ve konuşmalar bitikten sonra sahnenin altından çıkarmak gibi çılgın bir yöntem denedik. Çılgın diyorum çünkü bunu kapalı bir ortamda teknik olanakları her şeyi yerinde olan bir yerde yapmak çok kolay ama açık alanda yapıyorsunuz, yağmur riski var, zemine belli bir eğim vermek zorundasınız, hidrolik sistemler kendi içinde dengede olmak zorunda yani milimetrik hataları bile affetmeyecek bir çözüm üretmeniz lazım ve planladığınız her şey o anda o otomobillerin oradan çıkmasına bağlı. Eğer olmasaydı sadece bizim için değil o anı bekleyen milyonlarca insan için hayal kırıklığı olurdu. Bunun olmaması için ne gerekiyorsa planladık\" şeklinde konuştu. ETKİNLİK 4 DİLDE GERÇEKLEŞTİRİLDİİşe başlarken bin 557 kişilik bir oturma düzeni planladıklarını ancak son gece yeniden düzenlemeler yaptıklarını belirten Karadeniz, \"Baktık bu 2 binlerin üzerine çıkacak ve elemek çok mümkün değil. 2 bin 100 kişilik bir oturma düzeni planladık ve salon tamamen doldu, bir kişilik bile yer yoktu. Ayrıca 500 civarında da basın mensubu takip etti. Biz bütün etkinliği Türkçe dahil 4 dilde yaptık. Hem içeride simultane yaptık hem de uyduya çıktık. Bütün dünyaya yayın yaptık.\" şeklinde konuştu. \"7 BÖLGEYİ DOLAŞACAK VE VATANDAŞLARLA BULUŞACAK\"Karadeniz, gösterim araçlarının Türkiye\\'de dolaştırılması ve vatandaşlara gösterilmesi yönündeki beklentilere ilişkin de değerlendirmelerde bulundu. Vatandaşların aracı görme isteğinin farkında olduklarını vurgulayan Karadeniz, sözlerini şöyle tamamladı: \"Ben bunu TOGG CEO\\'muz Gürcan Karakaş ve Pazarlama Müdürü Çağ Günaçar\\'ın marka lansmanı sırasında böyle bir projelerinin olduğunu biliyorum. Gürcan Bey de Çağ Bey de sonraki dönemlerde bu tip planlamalar yapacaklarından bahsettiler. Ama bugün için erken. Çünkü önceki gün yaptığımız bir ön gösterimdi yani bir lansman bile değildi aslında. Marka lansmanı daha sonraki bir aşama ve marka lansmanıyla birlikte bildiğim kadarıyla araçlar 7 bölgeyi dolaşacak ve vatandaşlarla buluşturulacak. Türk insanı bunu hak ediyor. Yıllardır beklediğimiz bir şeydi bu. Herkesin belki yakından görmesi, temas etmesi, dokunması çok katkı sağlayacaktır. Pazarlama stratejisi olarak da çok katkı sağlayacaktır.\" Kaynak: Anadolu Ajansı')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B0EmcH8jdgt",
        "outputId": "2aaf4b51-74fd-4a68-a698-224d6e18680e"
      },
      "source": [
        "# Check the words in sentences\n",
        "(len(df['ctext'][15].split(' '))), (len(df['text'][15].split(' ')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(220, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP0blrsjnLmI"
      },
      "source": [
        "#Save the csv file to data\n",
        "df.to_csv('temiz_turkce_haber_4k.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5gCJGeoOebF",
        "outputId": "aadd8f6a-bfb1-49c8-a91d-4854c8ad1c01"
      },
      "source": [
        "!pip install transformers -q\n",
        "!pip install wandb -q\n",
        "!pip install sentencepiece\n",
        "#!curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "#!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.3MB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 52.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 53.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 37.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 28.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKNe2Uq0O_UD"
      },
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51zfbFoO_eM",
        "outputId": "0ab9acc0-7a67-47c9-8908-e025c93a2892"
      },
      "source": [
        "# Checking out the GPU we have access to. This is output is from the google colab version. \n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 26 21:29:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl-h0w_tO_iQ"
      },
      "source": [
        "## # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "#device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3vUMgheRERM",
        "outputId": "01aa8a8b-a4e3-44db-de19-8d48c2709885"
      },
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJPewkMZO_lc"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.text\n",
        "        self.ctext = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL-8tMimPqHx"
      },
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        labels = y[:, 1:].clone().detach() # lm_labels instead of labels\n",
        "        labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJwFwZUPPqPg"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQzTOdhBPqWf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c9d79f4e3ab44791a7ce0284ca2c20db",
            "c807b061fa1b4eaa9cd890e5c31d340f",
            "24785a5803f0474eb7ecd4b368ff3ec7",
            "d13fd0af7da941e5905c6e4d545528ec",
            "0ae4cfd2fc0649ec9b6166c9621f35f4",
            "a775ac7967984587b9333ac7ecd49e72",
            "984748470cae4d36bb2e1a3d77fccd5e",
            "5cfdf15b5f3e4c2f9fd1e63b446f2568"
          ]
        },
        "outputId": "352bbbfa-c71f-47b8-ceb2-ba0302daeb78"
      },
      "source": [
        "def main():\n",
        "    # WandB – Initialize a new run\n",
        "    wandb.init(project=\"transformers_T5_fine_tuning\")\n",
        "\n",
        "    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "    # Defining some key variables that will be used later on in the training  \n",
        "    config = wandb.config          # Initialize config\n",
        "    config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "    config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "    config.TRAIN_EPOCHS = 2        # number of epochs to train (default: 10)\n",
        "    config.VAL_EPOCHS = 1 \n",
        "    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "    config.SEED = 42               # random seed (default: 42)\n",
        "    config.MAX_LEN = 512           # 512\n",
        "    config.SUMMARY_LEN = 150        # 150\n",
        "    #truncation=True\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(config.SEED) # pytorch random seed\n",
        "    np.random.seed(config.SEED) # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # tokenzier for encoding the text\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "    \n",
        "\n",
        "    # Importing and Pre-Processing the domain data\n",
        "    # Selecting the needed columns only. \n",
        "    # Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "    df = pd.read_csv('temiz_turkce_haber_4k.csv')\n",
        "    df = df[['text','ctext']]\n",
        "    df.ctext = 'summarize: ' + df.ctext\n",
        "    print(df.head())\n",
        "\n",
        "    \n",
        "    # Creation of Dataset and Dataloader\n",
        "    # Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "    train_size = 0.8\n",
        "    train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
        "    val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    print(\"FULL Dataset: {}\".format(df.shape))\n",
        "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "    # Defining the parameters for creation of dataloaders\n",
        "    train_params = {\n",
        "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    val_params = {\n",
        "        'batch_size': config.VALID_BATCH_SIZE,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "    \n",
        "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    # Log metrics with wandb\n",
        "    wandb.watch(model, log=\"all\")\n",
        "    # Training loop\n",
        "    print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "    for epoch in range(config.TRAIN_EPOCHS):\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "    # Saving the dataframe as predictions.csv\n",
        "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "    for epoch in range(config.VAL_EPOCHS):\n",
        "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "        final_df.to_csv('predictions.csv')\n",
        "        print('Output Files generated for review')\n",
        "\n",
        "\n",
        "    # Saving Fine Tuned Model\n",
        "    output_dir = '/content'\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "    model_to_save.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:1ay0q02m) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 546<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9d79f4e3ab44791a7ce0284ca2c20db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210526_214700-1ay0q02m/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210526_214700-1ay0q02m/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Training Loss</td><td>1.13651</td></tr><tr><td>_runtime</td><td>1827</td></tr><tr><td>_timestamp</td><td>1622067451</td></tr><tr><td>_step</td><td>360</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Training Loss</td><td>▅▆▅█▄▆▅▆▆▄▅▅▄▂▅▄▄▂▂▅▁▂▂▂▃▂▃▁▂▁▃▁▁▂▁▃▂▂▂▃</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">lively-dream-28</strong>: <a href=\"https://wandb.ai/ardaozmen/transformers_T5_fine_tuning/runs/1ay0q02m\" target=\"_blank\">https://wandb.ai/ardaozmen/transformers_T5_fine_tuning/runs/1ay0q02m</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1ay0q02m). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">polished-smoke-29</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ardaozmen/transformers_T5_fine_tuning\" target=\"_blank\">https://wandb.ai/ardaozmen/transformers_T5_fine_tuning</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ardaozmen/transformers_T5_fine_tuning/runs/2x3ni5oj\" target=\"_blank\">https://wandb.ai/ardaozmen/transformers_T5_fine_tuning/runs/2x3ni5oj</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210526_221731-2x3ni5oj</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "                                                text                                              ctext\n",
            "0  Iğdır'da, Umut adlı erkek evi terk eden 1 çocu...  summarize: Iğdır'da bir kişi, tartıştığı karıs...\n",
            "1  Karsan Otomotiv'den yapılan açıklamada iş insa...  summarize: Cumhurbaşkanı Recep Tayyip Erdoğan'...\n",
            "2  Türkiye'nin Otomobili'nin, Bilişim Vadisi'nde ...  summarize: Türkiye'nin Otomobili'nin, Bilişim ...\n",
            "3  Van'ın Erciş ilçesinde evden çıktıktan sonra b...  summarize: Van'ın Erciş ilçesinde evden çıktık...\n",
            "4  Dünyaca ünlü şarkıcı Rita Ora, annesi Vera Ora...  summarize: Son dönemin parlayan yıldızlarından...\n",
            "FULL Dataset: (4484, 2)\n",
            "TRAIN Dataset: (3587, 2)\n",
            "TEST Dataset: (897, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n",
            "Epoch: 0, Loss:  5.8043365478515625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  2.1652960777282715\n",
            "Epoch: 0, Loss:  1.3832365274429321\n",
            "Epoch: 0, Loss:  0.4993664026260376\n",
            "Epoch: 1, Loss:  0.7837203145027161\n",
            "Epoch: 1, Loss:  0.7894322872161865\n",
            "Epoch: 1, Loss:  0.7884302735328674\n",
            "Epoch: 1, Loss:  0.7475789785385132\n",
            "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n",
            "Completed 0\n",
            "Completed 100\n",
            "Completed 200\n",
            "Completed 300\n",
            "Completed 400\n",
            "Output Files generated for review\n",
            "Saving model to /content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "LnAjXcpQvZMR",
        "outputId": "a0362b83-0351-4999-dbee-904a8f550917"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pred = pd.read_csv('predictions.csv')\n",
        "pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Tekneyle çktklar deniz turunun keyfini çkard. ...</td>\n",
              "      <td>Dünyaca ünlü şarkc Rita Ora, annesi Vera Ora i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Yeliz Kuvanc, 'Tutunamayanlar' dizide başrolle...</td>\n",
              "      <td>Güzel oyuncu Yeliz Kuvanc, TRT'nin iddial absü...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Ankara Valisi Vasip ahin, devam eden kar yaşnn...</td>\n",
              "      <td>Ankara Valisi Vasip ahin, kentte devam eden ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sivri dilinden dolay girdii polemiklerle sk sk...</td>\n",
              "      <td>Cumhurbaşkan Recep Tayyip Erdoan' ziyaret eden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>arkc, 55 bin TL marka çantasn modelleri ilk ke...</td>\n",
              "      <td>Son dönemin çok konuşulan ismi Aleyna Tilki, 5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        Actual Text\n",
              "0           0  ...  Dünyaca ünlü şarkc Rita Ora, annesi Vera Ora i...\n",
              "1           1  ...  Güzel oyuncu Yeliz Kuvanc, TRT'nin iddial absü...\n",
              "2           2  ...  Ankara Valisi Vasip ahin, kentte devam eden ka...\n",
              "3           3  ...  Cumhurbaşkan Recep Tayyip Erdoan' ziyaret eden...\n",
              "4           4  ...  Son dönemin çok konuşulan ismi Aleyna Tilki, 5...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrV7hDEOvozO",
        "outputId": "c94a6c51-d306-4132-8304-590fb3e8455e"
      },
      "source": [
        "pred['Generated Text'][1], pred['Actual Text'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Yeliz Kuvanc, 'Tutunamayanlar' dizide başrollerini paylaşt dizide, Tark rolünü canlandran ünlü oyuncu Dou Demirkol'un ablas Ayşe karakteriyle izleyiciyle buluşmaya hazrlanyor.\",\n",
              " \"Güzel oyuncu Yeliz Kuvanc, TRT'nin iddial absürt komedisi olan Tutunamayanlar ile ekranlara dönüyor. Kuvanc dizide başrol oyuncusu Dou Demirkol'un ablas Ayşe karakterini canlandracak.\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvKNCiuhPqcY"
      },
      "source": [
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Loading Fine Tuned Model\n",
        "output_dir = '/content'\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = T5ForConditionalGeneration.from_pretrained(output_dir)\n",
        "tokenizer = T5Tokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "#model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feQAGzmGPqib"
      },
      "source": [
        "#Summarize function\n",
        "def summarize(text, max_length=150):\n",
        "  \n",
        "  input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)\n",
        "\n",
        "  generated_ids = model.generate(input_ids=input_ids, num_beams=2, max_length=max_length,  repetition_penalty=2.5, length_penalty=1.0, early_stopping=True)\n",
        "\n",
        "  preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "\n",
        "  return preds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISQ8DT1Pqor",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "214a8759-7661-4d1b-91f7-d78b9ecde86f"
      },
      "source": [
        "#Testing\n",
        "summarize(\"\"\"\n",
        "Galatasaray'da tarihi seçime sayılı günler kala eski başkan Ünal Aysal'dan çarpıcı bir hamle geldi. \\n\n",
        " Birçok başkan adayının çıkması sonrası Aysal, Adnan Öztürk ve Sedat Doğan'ında katılacağı bir toplantı yapma kararı aldı. \\n\n",
        " Burak Elmas ve Eşref Hamamcıoğlu'nun da davet edileceği toplantı da Aysal'ın adaylara birleşme teklifi yapması bekleniyor. \\n\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"başkan adaynn çkmas sonras Aysal, Burak Elmas ve Sedat Doan'nda katlaca bir toplant yapma karar ald. Galatasaray'da tarihi seçime sayl günler kala eski başkan çarpc bir hamle geldi.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UjIkAhoPqu5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}