{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"textrank-sentence-extraction-using-nltk.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPQRgUJkCl2PeS6xMG+fPEt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vke3leHmanaE","executionInfo":{"status":"ok","timestamp":1611677026306,"user_tz":-180,"elapsed":44364,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}},"outputId":"52fb3852-49ec-4a6a-fa2d-b946fe16fe53"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-eLvQD22dIsw","executionInfo":{"status":"ok","timestamp":1611677036050,"user_tz":-180,"elapsed":1526,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}},"outputId":"73a3fabc-f15d-4746-c865-2fef73bdc706"},"source":["!ls \"/gdrive/MyDrive/NLP/textrank\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["news_summary.csv  news_summary_more.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BMEmXIhZdVO_","executionInfo":{"status":"ok","timestamp":1611677044153,"user_tz":-180,"elapsed":657,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}}},"source":["import os\n","os.chdir(\"/gdrive/MyDrive/NLP/textrank\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKoH6pjFdejV","executionInfo":{"status":"ok","timestamp":1611677051698,"user_tz":-180,"elapsed":1756,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}}},"source":["import pandas as pd\n","\n","db = pd.read_csv('news_summary_more.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfC5mzsPdn9n","executionInfo":{"status":"ok","timestamp":1611677053343,"user_tz":-180,"elapsed":909,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}}},"source":["text_str=db['text'][0]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"_SFoVimcpJrk","executionInfo":{"status":"ok","timestamp":1611677055067,"user_tz":-180,"elapsed":665,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}},"outputId":"4afb2311-be2e-4301-f8fa-f482a92a23d9"},"source":["db['text'][1]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\""]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmH3bZmSfv_A","executionInfo":{"status":"ok","timestamp":1611677066734,"user_tz":-180,"elapsed":1378,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}},"outputId":"25f1536d-a0f9-4453-89bb-6e885ae96d9f"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"xSb5pVROdt_B","executionInfo":{"status":"ok","timestamp":1611677087927,"user_tz":-180,"elapsed":699,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}}},"source":["from nltk import sent_tokenize, word_tokenize\n","\n","sentences = sent_tokenize(text_str)\n","tokenized_sentences = [word_tokenize(sent) for sent in sentences]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_0eDWJWfnOb","executionInfo":{"status":"ok","timestamp":1611677109918,"user_tz":-180,"elapsed":731,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}}},"source":["from nltk.cluster.util import cosine_distance\n","\n","def build_similarity_matrix(sentences, stopwords=None):\n","    # create an empty similarity matrix\n","    sm = np.zeros([len(sentences), len(sentences)])\n","\n","    for idx1 in range(len(sentences)):\n","        for idx2 in range(len(sentences)):\n","            if idx1 == idx2:\n","                continue\n","\n","            sm[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stopwords=stopwords)\n","\n","    # Get Symmeric matrix\n","    sm = get_symmetric_matrix(sm)\n","\n","    # Normalize matrix by column\n","    norm = np.sum(sm, axis=0)\n","    sm_norm = np.divide(sm, norm, where=norm != 0)  # this is to ignore the 0 element in norm\n","\n","    return sm_norm\n","\n","def _sentence_similarity(sent1, sent2, stopwords=None):\n","    if stopwords is None:\n","        stopwords = []\n","\n","    sent1 = [w.lower() for w in sent1]\n","    sent2 = [w.lower() for w in sent2]\n","\n","    all_words = list(set(sent1 + sent2))\n","\n","    vector1 = [0] * len(all_words)\n","    vector2 = [0] * len(all_words)\n","\n","    # build the vector for the first sentence\n","    for w in sent1:\n","        if w in stopwords:\n","            continue\n","        vector1[all_words.index(w)] += 1\n","\n","    # build the vector for the second sentence\n","    for w in sent2:\n","        if w in stopwords:\n","            continue\n","        vector2[all_words.index(w)] += 1\n","\n","    return core_cosine_similarity(vector1, vector2)\n","    \n","def core_cosine_similarity(vector1, vector2):\n","    \"\"\"\n","    measure cosine similarity between two vectors\n","    :param vector1:\n","    :param vector2:\n","    :return: 0 < cosine similarity value < 1\n","    \"\"\"\n","    return 1 - cosine_distance(vector1, vector2)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"kG57IWBhgAQ3","executionInfo":{"status":"ok","timestamp":1611677166746,"user_tz":-180,"elapsed":686,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}}},"source":["def run_page_rank(similarity_matrix):\n","\n","    # constants\n","    damping = 0.85  # damping coefficient, usually is .85\n","    min_diff = 1e-5  # convergence threshold\n","    steps = 100  # iteration steps\n","\n","    pr_vector = np.array([1] * len(similarity_matrix))\n","\n","    # Iteration\n","    previous_pr = 0\n","    for epoch in range(steps):\n","        pr_vector = (1 - damping) + damping * np.matmul(similarity_matrix, pr_vector)\n","        if abs(previous_pr - sum(pr_vector)) < min_diff:\n","            break\n","        else:\n","            previous_pr = sum(pr_vector)\n","\n","    return pr_vector"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUhvLqgzg2aj","executionInfo":{"status":"ok","timestamp":1611677190650,"user_tz":-180,"elapsed":637,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}}},"source":["def get_top_sentences(pr_vector, sentences, number=5):\n","\n","    top_sentences = []\n","\n","    if pr_vector is not None:\n","\n","        sorted_pr = np.argsort(pr_vector)\n","        sorted_pr = list(sorted_pr)\n","        sorted_pr.reverse()\n","\n","        index = 0\n","        for epoch in range(number):\n","            sent = sentences[sorted_pr[index]]\n","            sent = normalize_whitespace(sent)\n","            top_sentences.append(sent)\n","            index += 1\n","\n","    return top_sentences"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XzGpzxkEg62G","executionInfo":{"status":"ok","timestamp":1611677409362,"user_tz":-180,"elapsed":673,"user":{"displayName":"Arda Ozmen","photoUrl":"https://lh4.googleusercontent.com/-N51MAYwNwQ0/AAAAAAAAAAI/AAAAAAAAANk/Y2P-exym_CE/s64/photo.jpg","userId":"11855138172993245603"}},"outputId":"f44e8273-2285-4c7f-fb09-47be61315b70"},"source":["import re\n","\n","import numpy as np\n","from nltk import sent_tokenize, word_tokenize\n","\n","from nltk.cluster.util import cosine_distance\n","\n","MULTIPLE_WHITESPACE_PATTERN = re.compile(r\"\\s+\", re.UNICODE)\n","\n","\n","def normalize_whitespace(text):\n","    \"\"\"\n","    Translates multiple whitespace into single space character.\n","    If there is at least one new line character chunk is replaced\n","    by single LF (Unix new line) character.\n","    \"\"\"\n","    return MULTIPLE_WHITESPACE_PATTERN.sub(_replace_whitespace, text)\n","\n","\n","def _replace_whitespace(match):\n","    text = match.group()\n","\n","    if \"\\n\" in text or \"\\r\" in text:\n","        return \"\\n\"\n","    else:\n","        return \" \"\n","\n","\n","def is_blank(string):\n","    \"\"\"\n","    Returns `True` if string contains only white-space characters\n","    or is empty. Otherwise `False` is returned.\n","    \"\"\"\n","    return not string or string.isspace()\n","\n","\n","def get_symmetric_matrix(matrix):\n","    \"\"\"\n","    Get Symmetric matrix\n","    :param matrix:\n","    :return: matrix\n","    \"\"\"\n","    return matrix + matrix.T - np.diag(matrix.diagonal())\n","\n","\n","def core_cosine_similarity(vector1, vector2):\n","    \"\"\"\n","    measure cosine similarity between two vectors\n","    :param vector1:\n","    :param vector2:\n","    :return: 0 < cosine similarity value < 1\n","    \"\"\"\n","    return 1 - cosine_distance(vector1, vector2)\n","\n","\n","'''\n","Note: This is not a summarization algorithm. This Algorithm pics top sentences irrespective of the order they appeared.\n","'''\n","\n","\n","class TextRank4Sentences():\n","    def __init__(self):\n","        self.damping = 0.85  # damping coefficient, usually is .85\n","        self.min_diff = 1e-5  # convergence threshold\n","        self.steps = 100  # iteration steps\n","        self.text_str = None\n","        self.sentences = None\n","        self.pr_vector = None\n","\n","    def _sentence_similarity(self, sent1, sent2, stopwords=None):\n","        if stopwords is None:\n","            stopwords = []\n","\n","        sent1 = [w.lower() for w in sent1]\n","        sent2 = [w.lower() for w in sent2]\n","\n","        all_words = list(set(sent1 + sent2))\n","\n","        vector1 = [0] * len(all_words)\n","        vector2 = [0] * len(all_words)\n","\n","        # build the vector for the first sentence\n","        for w in sent1:\n","            if w in stopwords:\n","                continue\n","            vector1[all_words.index(w)] += 1\n","\n","        # build the vector for the second sentence\n","        for w in sent2:\n","            if w in stopwords:\n","                continue\n","            vector2[all_words.index(w)] += 1\n","\n","        return core_cosine_similarity(vector1, vector2)\n","\n","    def _build_similarity_matrix(self, sentences, stopwords=None):\n","        # create an empty similarity matrix\n","        sm = np.zeros([len(sentences), len(sentences)])\n","\n","        for idx1 in range(len(sentences)):\n","            for idx2 in range(len(sentences)):\n","                if idx1 == idx2:\n","                    continue\n","\n","                sm[idx1][idx2] = self._sentence_similarity(sentences[idx1], sentences[idx2], stopwords=stopwords)\n","\n","        # Get Symmeric matrix\n","        sm = get_symmetric_matrix(sm)\n","\n","        # Normalize matrix by column\n","        norm = np.sum(sm, axis=0)\n","        sm_norm = np.divide(sm, norm, where=norm != 0)  # this is ignore the 0 element in norm\n","\n","        return sm_norm\n","\n","    def _run_page_rank(self, similarity_matrix):\n","\n","        pr_vector = np.array([1] * len(similarity_matrix))\n","\n","        # Iteration\n","        previous_pr = 0\n","        for epoch in range(self.steps):\n","            pr_vector = (1 - self.damping) + self.damping * np.matmul(similarity_matrix, pr_vector)\n","            if abs(previous_pr - sum(pr_vector)) < self.min_diff:\n","                break\n","            else:\n","                previous_pr = sum(pr_vector)\n","\n","        return pr_vector\n","\n","    def _get_sentence(self, index):\n","\n","        try:\n","            return self.sentences[index]\n","        except IndexError:\n","            return \"\"\n","\n","    def get_top_sentences(self, number=5):\n","\n","        top_sentences = []\n","\n","        if self.pr_vector is not None:\n","\n","            sorted_pr = np.argsort(self.pr_vector)\n","            sorted_pr = list(sorted_pr)\n","            sorted_pr.reverse()\n","\n","            index = 0\n","            for epoch in range(number):\n","                sent = self.sentences[sorted_pr[index]]\n","                sent = normalize_whitespace(sent)\n","                top_sentences.append(sent)\n","                index += 1\n","\n","        return top_sentences\n","\n","    def analyze(self, text, stop_words=None):\n","        self.text_str = text\n","        self.sentences = sent_tokenize(self.text_str)\n","\n","        tokenized_sentences = [word_tokenize(sent) for sent in self.sentences]\n","\n","        similarity_matrix = self._build_similarity_matrix(tokenized_sentences, stop_words)\n","\n","        self.pr_vector = self._run_page_rank(similarity_matrix)\n","\n","text_str='''One day the Hare laughed at the short feet and slow speed of the Tortoise. The Tortoise replied:\n","\n","\"You may be as fast as the wind, but I will beat you in a race!\"\n","\n","The Hare thought this idea was impossible and he agreed to the proposal. It was agreed that the Fox should choose the course and decide the end.\n","\n","The day for the race came, and the Tortoise and Hare started together.\n","\n","The Tortoise never stopped for a moment, walking slowly but steadily, right to the end of the course. The Hare ran fast and stopped to lie down for a rest. But he fell fast asleep. Eventually, he woke up and ran as fast as he could. But when he reached the end, he saw the Tortoise there already, sleeping comfortably after her effort.'''\n","\n","\n","tr4sh = TextRank4Sentences()\n","tr4sh.analyze(text_str)\n","print(tr4sh.get_top_sentences(2))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["['The day for the race came, and the Tortoise and Hare started together.', 'The Tortoise never stopped for a moment, walking slowly but steadily, right to the end of the course.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Edq8Hy6jptZN"},"source":[""],"execution_count":null,"outputs":[]}]}